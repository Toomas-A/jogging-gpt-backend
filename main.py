from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse
from dotenv import load_dotenv
import os
import openai
import uvicorn

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

from fastapi.middleware.cors import CORSMiddleware  # üëà –ü–µ—Ä–µ–º–µ—Å—Ç–∏ –∏–º–ø–æ—Ä—Ç –≤ –Ω–∞—á–∞–ª–æ

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # üëà –º–æ–∂–µ—à—å –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ ["https://toomas-a.github.io"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/", response_class=HTMLResponse)
async def root():
    return """
    <html>
      <head><title>Jogging GPT</title></head>
      <body>
        <h1>üëü Welcome to Jogging GPT!</h1>
        <p>Server is running successfully ‚úÖ</p>
      </body>
    </html>
    """

@app.post("/gpt")
async def ask_gpt(request: Request):
    body = await request.json()
    prompt = body.get("prompt")

    if not prompt:
        return {"error": "‚ùå Prompt is missing!"}

    print("üì® –ü–æ–ª—É—á–µ–Ω prompt:", prompt)

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        answer = response.choices[0].message["content"]
        return {"response": answer}
    except Exception as e:
        print("üö® GPT error:", str(e))
        return {"error": f"‚ö†Ô∏è GPT error: {str(e)}"}

# –ó–∞–ø—É—Å–∫ –Ω–∞ Render
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run("main:app", host="0.0.0.0", port=port)
